---
title: "Exploring *Bacteroides* molecular variation"
engine: knitr
format:
  html:
    code-fold: true
    code-summary: "Show the code"
---

## Connecting *Bacteroides* 16S ASVs to genomic species-level variation

### Retrieving Yan et al 2022 metagenomic reads

We started working with the metagenomic dataset that was published in the [Scientific Data paper by Yan et al 2022](https://www.nature.com/articles/s41597-022-01302-9). This includes a nested subset of 395 metagenomic libraries from the allo-HCT patient population that was profiled with 16S.

We first need to get the list of SRA accessions:

```{r, eval=FALSE}
# Load required library
suppressMessages(library(tidyverse))

# Load table with stool sample metadata
accessions <- suppressMessages(
        read_csv("data/tblASVsamples.csv",
            col_types = cols(
                .default = col_guess(),
                Pool = col_character())) %>%
        filter(!is.na(AccessionShotgun)) %>%
        select(AccessionShotgun, SampleID) %>%
        mutate(SampleID = paste0("s_", SampleID)) %>% # to ensure all filenames start with a letter rather than a number
        distinct())

# Save accessions to misc file
write_tsv(accessions, "misc_files/bacteroides_variation/yan_sd_2022_accessions.txt", col_names = FALSE)
```

Now we can dowdload the reads from SRA, sort them, and rename them with the sample names:
```{bash, eval=FALSE}
# Make directory for raw reads
mkdir -p data/reads/yan_sd_2022

# Fetch, sort and rename reads
sbatch code/scripts/bacteroides_variation/fetch_yan_reads.sh

# Clear SRA cache
rm -r /data1/xavierj/carlos/sra_repo/sra/*
```

### Assembling *Bacteroides* MAGs with Kraken2 binning

#### Enriching Kraken database with Baceroides genomes from NCBI

I downloaded all genomes of *Bacteroides* from the NCBI database on April 18th, 2025, and extracted the metadata to a CSV:

```{bash, eval=FALSE}
# Download genomes from NCBI

# NCBI CLI toolkit
conda activate ncbi

# Output directory
bacteroides_genome_dir="analyses/bacteroides_variation/genomes/ncbi"
mkdir -p ${bacteroides_genome_dir}

# Download all Bacteroides genomes
datasets download genome taxon "Bacteroides" --dehydrated --filename ${bacteroides_genome_dir}/bacteroides_genomes.zip

# Extract and rehydrate the files
unzip ${bacteroides_genome_dir}/bacteroides_genomes.zip -d ${bacteroides_genome_dir}
datasets rehydrate --directory ${bacteroides_genome_dir}


# Sort and relabel genome files

# Create directory for all .fna files
mkdir -p analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/fastas

# Find and move all .fna files to the new directory
find analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/data/ -not -path "analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/fastas/*" -type f -name "*.fna" -exec mv {} analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/fastas/ \;

# Create directory for relabeled fastas
mkdir -p analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/relabeled_fastas

# Copy and rename files
for file in analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/fastas/*; do
  base=$(basename "$file")
  new_name="${base%%.*}.fna"
  mv "$file" "analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/relabeled_fastas/$new_name"
done


# Extract genome metadata to CSV

# Python env
conda activate python3

# Tabulate genome metadata
python software/custom/ncbi_jsonl_to_csv.py analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/data/assembly_data_report.jsonl analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/genome_metadata.csv

# Switch to R env
conda activate r-4.4.2
```

This downloaded 15,412 genomes. I filtered them to include only the ones with checkM completeness > 90% and checkM contamination < 5%. This resulted in 7,136 genomes:

```{r, eval=FALSE}
# Load genome metadata file
sampled_genomes <- read_csv("analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/genome_metadata.csv") %>%
  filter(checkm_completeness >= 90 & checkm_contamination <= 5) %>% 
  mutate(file = str_remove(accession, "\\..*$")) %>%
  select(file, taxid)

# Save CSV
write_csv(sampled_genomes, "analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/sampled_genomes.csv", col_names = FALSE)
```

I had to add the NCBI Tax ID to the headers of the selected genomes before adding them to the kraken database:

```{bash, eval=FALSE}
sh software/custom/taxid_to_headers.sh \
  -c analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/sampled_genomes.csv \
  -d analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/relabeled_fastas \
  -o analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/kraken_header_fastas > \
  analyses/bacteroides_variation/genomes/ncbi/ncbi_dataset/header_trim.log
```

After this, I created a kraken db that included the *Bacteroides* genomes:

```{bash, eval=FALSE}
sbatch code/scripts/bacteroides_variation/build_kraken_db_18042025.sh
```

#### Read binning and assembly

```{bash, eval=FALSE}
sbatch code/scripts/bacteroides_variation/classify_assemble.sh
```

### Assembling *Bacteroides* MAGs with VAMB binning

I preprocessed the reads with fastp and generated a metagenomic assembly with metaSPAdes for each metagenomic library:

```{bash, eval=FALSE}
# Metagenome
sbatch code/scripts/bacteroides_variation/yan_sd_2022_metaspades.sh
# Plasmids
sbatch code/scripts/bacteroides_variation/yan_sd_2022_metaplasmid.sh
```

### Extracting 16S sequences

I created a HMMER profile of 16S rRNA sequences using the seed alignment of the [Rfam RF00177](https://rfam.org/family/RF00177#tabview=tab2):

```{bash, eval=false}
#mkdir -p hmms/16S
conda activate hmmerseqkit
hmmbuild hmms/16S/RF00177_16S.hmm hmms/16S/RF00177.stockholm.txt

# Test extraction tool
sh software/custom/nhmmer_extract.sh -p hmms/16S/RF00177_16S.hmm \
  -e 0 \
  -i analyses/bacteroides_variation/genomes/kraken_binning/bacteroides_metaspades/s_1042AA/contigs.fasta \
  -o test.fa \
  -t hits.txt \
  -c 1
```

**Why do I consistently get 2 16S copies (one from a *Bacteroides* and one from what seems to be a *Blautia*) from the metagenomes assembled from binned reads??**